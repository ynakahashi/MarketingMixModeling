---
title: "広告効果を推定しつつ回帰を回したい"
author: Y.Nakahashi
date: 2018-03-15
output: html_notebook
---

### 背景
しつこいようですが、*Marketing Mix Modeling*（*MMM*）の話題です。

先日、[こんな面白い論文](https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/45999.pdf)を見つけました。
GoogleのResearcherによるMMMの論文（彼らはMedia Mix Modelingと呼んでいます）なのですが、彼らは**ヒルの式**を用いて広告のShape効果（Carveture効果）を推定するということをやっています。ここでShape効果・carveture効果とは、メディアの露出量に対する目的変数の反応を示す曲線を指すようで、ヒルの式とは：

$$
H(x; K, S) = \frac{1}{1 + (\frac{x}{K})^{-S}}
$$
であり、$K > 0$や$S > 0$となるパラメータによってLogやSigmoidの形状を表現することができるもののようです。
ここでヒルの式によってxがどのような形状となるかを確認してみましょう。まずはヒルの式を以下のように定義します。

```{r}
hill_transformation <- function(x, k, s) {
   1 / (1 + (x / k)^-s)
}
```

続いて、パラメータとなる`k`と`s`をそれぞれ以下のように設定した場合をプロットしてみましょう。なおこの数値は論文から拝借しています。

```{r}
x <- seq(0, 1, by = 0.05)

plot(x, hill_transformation(x, 0.4, 4), 
     type = "l", col = 2, xlim = c(0, 1), ylim = c(0, 1),
     ylab = "Hill Transformed Value")
par(new = T)
plot(x, hill_transformation(x, 0.4, 1), 
     type = "l", col = 3, xlim = c(0, 1), ylim = c(0, 1), axes = F,
     ylab = "")
par(new = T)
plot(x, hill_transformation(x, 0.8, 4), 
     type = "l", col = 4, xlim = c(0, 1), ylim = c(0, 1), axes = F,
     ylab = "")
par(new = T)
plot(x, hill_transformation(x, 0.8, 1), 
     type = "l", col = 5, xlim = c(0, 1), ylim = c(0, 1), axes = F,
     ylab = "")
legend("topleft", legend = c("k = 0.4, s = 4", "k = 0.4, s = 1", 
                             "k = 0.8, s = 4", "k = 0.8, s = 1"), 
       col = c(2:5), lty = rep(1, 4))
```

このように、パラメータを変更することで元の値を柔軟に変換することが可能です。

これまで私が書いてきた記事では、いずれも広告効果（回帰係数）そのものを推定する方法にばかり注目しており、説明変数の"効き方"については触れてきませんでした。これは、広告の効果は出稿が増すにつれて段々と減少していくことを仮定することが多く、対数を取ることでそういった飽和を表現できるためです。また両対数モデル（yとxの両方を対数変換したモデル）であれば回帰係数がそのまま弾力性になるという性質を持つため便利であり、安易に対数変換を選択していました。しかし、これではちょっと検討が足りないと言われても仕方ありません。

というわけで本エントリーでは、ヒルの式により変換したXを用いてシミュレーションデータを発生させ、元のXから変数変換のためのパラメータを推定できるかを検証したいと思います。なお元論文ではAd-Stock効果としてGeometric Ad-Stock：

$$
GA(x_{t}; \alpha, L) = \frac{\sum_{l = 0}^{L}x_{t-l}\alpha^{l}}{\sum_{l = 0}^{L}\alpha^{l}}
$$

を用いていますが、今回の検証の対象外なのでAd-Stock効果としてはいつも通りKoyck型のものとします。



#### ライブラリの読み込み
今回の分析でも`{rstan}`を使用します。

```{r}
library(tidyverse)
library(ggplot2)
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

#### シミュレーションデータの生成
分析用のデータを以下のように生成します。特別なことは何もしておらず、与えた数値にしたがって目的変数`y`と説明変数`X1`および`X2`を作成します。

```{r}
## データ生成用の関数を定義
simulate_y <- function(pars) {
   n         <- pars[1]  # num of observation
   mu        <- pars[2]  # intercept
   beta_01   <- pars[3]  # regression coefficient of X1 to be esitmated
   beta_02   <- pars[4]  # regression coefficient of X2 to be esitmated
   lambda_01 <- pars[5]  # decay rate of Ad-Stock effect of X1
   lambda_02 <- pars[6]  # decay rate of Ad-Stock effect of X2
   k_01      <- pars[7]  # k for X1
   k_02      <- pars[8]  # k for X2
   s_01      <- pars[9]  # s for X1
   s_02      <- pars[10] # s for X2
   var_e     <- pars[11] # residual variance

   X_01_raw  <- rnorm(n, 100, 2)
   X_01_fil  <- stats::filter(X_01_raw, lambda_01, "recursive")
   X_01_conv <- hill_transformation(X_01_fil, k_01, s_01)
   
   X_02_raw  <- rnorm(n, 100, 2)
   X_02_fil  <- stats::filter(X_02_raw, lambda_02, "recursive")
   X_02_conv <- hill_transformation(X_02_fil, k_02, s_02)
   
   error <- rnorm(n, 0, sqrt(var_e))
   
   y     <- mu + beta_01 * X_01_conv + beta_02 * X_02_conv + error
   dat <- data.frame(
      "Y" = y,
      "X_01" = X_01_raw,
      "X_02" = X_02_raw
   )
   return(na.omit(dat))
}

## データ生成
set.seed(123)
pars <- c(100, 5, 0.8, 0.2, 0.7, 0.7, 0.4, 0.4, 4, 1, 1)
dat <- simulate_y(pars)
```

`X1`、`X2`それぞれについて、

 - 推定したい広告効果　⇒　`0.8`、`0.2`
 - Koyckラグの残存効果　⇒　ともに`0.7`
 - ヒルの式の`k`および`s`　⇒　`0.4`および`4`、`0.4`および`1`

と指定しています。これらのパラメータを、もとの`X1`および`X2`から推定することが狙いです。

#### optimによるフィッティング
手始めに*optim*を使ってフィッティングしてみましょう。これまでの記事でも度々*optim*を使ってきましたが、なかなか精度良く推定することが可能です。

```{r}
return_AIC <- function(param, dat) {
   beta_01   <- param[1]
   beta_02   <- param[2]
   lambda_01 <- param[3]
   lambda_02 <- param[4]
   k_01      <- param[5]
   k_02      <- param[6]
   s_01      <- param[7]
   s_02      <- param[8]
   
   dat$X_01_fil  <- stats::filter(dat$X_01, lambda_01, "recursive")
   dat$X_01_conv <- hill_transformation(dat$X_01_fil, k_01, s_01)
   dat$X_02_fil  <- stats::filter(dat$X_02, lambda_02, "recursive")
   dat$X_02_conv <- hill_transformation(dat$X_02_fil, k_02, s_02)
   
   AIC(lm(Y ~ X_01_conv + X_02_conv, dat))
}
### 適当な数値を入れてみる
return_AIC(rep(0.5, 8), dat)
# 273.1042
```

ではフィッティングしてみましょう。

```{r}
param <- rep(0.5, 8)
res_optim <- optim(par = optim(par = param, fn = return_AIC, dat = dat)$par,
                   fn = return_AIC, dat = dat)
```

少し時間がかかったのでイヤな予感がしますが、パラメータを確認してみると：

```{r}
true_par <- c(0.8, 0.2, 0.7, 0.7, 0.4, 0.4, 4, 1)
print(cbind(true_par, res_optim$par), digits = 2)
```

全く当たっていませんね。。


#### Stanによるフィッティング
では今度はStanを使ってみましょう。以下のように指定します。

```{r}
dat_Stan <- list(N        = nrow(dat),
                 Y        = dat$Y,
                 X_01     = dat$X_01,
                 X_02     = dat$X_02)
```

またStanのスクリプトは以下のようになります。

```{stan}
data {
   int N; // 地域ごとの観測値の数（data_length）
   int K; // 地域の数（num_region）
   vector[N*K] Y; // 観測値のベクトル
   vector[N*K] X; // 説明変数のベクトル
   int<lower=1, upper=K> Area_ID[N*K];
}

parameters {
   real state_t0;     // 状態変数の0期目の平均
   vector[N*K] state; // 状態変数のベクトル
   real beta_0;       // 回帰係数の事前分布の平均
   vector[K] beta;    // 地域ごとの回帰係数のベクトル
   real<lower=0> var_state_t0; // 状態変数の0期目の分散
   real<lower=0> var_state;    // 状態変数の分散
   real<lower=0> var_beta_0;   // 回帰係数の事前分布の分散
   real<lower=0> var_error;    // 誤差分散
}

model {
   // 状態変数をサンプリング
   for (k in 1:K) {
      // 1期目の値は0期目の分布からサンプルする
      state[1 + (k-1)*N] ~ normal(state_t0, var_state_t0);
      
      // 2期目以降は前期の値を平均とした分布からサンプルする
      for(i in 2:N) {
         state[i + (k-1)*N] ~ normal(state[i-1 + (k-1)*N], var_state);
      }
   }
   
   // 回帰係数をサンプリング
   for (k in 1:K) {
      beta[k] ~ normal(beta_0, var_beta_0);
   }

   // Yをサンプリング
   for(i in 1:(N*K)) {
      Y[i] ~ normal(state[i] + beta[Area_ID[i]] * X[i], var_error);
   }
}
```

上記のモデルを用いて、フィッティングを行います。

```{r}
fit_01 <- stan(file = '/Users/nakahashi/Desktop/Git/MarketingMixModeling/Hill_Transformation.stan',
               data = dat_Stan,
               iter = 3000,
               chains = 4,
               seed = 123)
```


#### 結果の確認
フィッティングが終わったので、結果を見てみましょう。`fit_01`からサンプルを抽出して加工します。

ダメだーー



```{r}
## サンプルを抽出する
res_01 <- rstan::extract(fit_01)

## 該当するパラメータを取り出す
ests <- summary(fit_01)$summary
t0_rows    <- rownames(ests)[grep("state_t0", rownames(ests))]
state_rows <- rownames(ests)[grep("state\\[", rownames(ests))]
b0_rows    <- rownames(ests)[grep("beta_0", rownames(ests))]
beta_rows  <- rownames(ests)[grep("beta\\[", rownames(ests))]

## 状態変数
state_par <- 
   ests %>% 
   data.frame %>% 
   select(mean) %>% 
   mutate("Par" = rownames(ests)) %>% 
   filter(Par %in% state_rows) %>% 
   mutate("Area" = DF$Area_ID)

state_cmp <- data.frame(
   True = State,
   Est = state_par$mean,
   Area = as.factor(state_par$Area),
   YM = DF$YM
)
```


```{r}
stan_trace(fit_01, pars = t0_rows)
stan_trace(fit_01, pars = state_rows[c(1, 49, 97, 145, 193)])
stan_trace(fit_01, pars = b0_rows)
stan_trace(fit_01, pars = beta_rows)
stan_trace(fit_01, pars = beta_rows, inc_warmup = T)
stan_hist(fit_01, pars = t0_rows)
stan_hist(fit_01, pars = state_rows[c(1, 49, 97, 145, 193)])
stan_hist(fit_01, pars = b0_rows)
stan_hist(fit_01, pars = beta_rows)
stan_hist(fit_01, pars = beta_rows)
```


まずは状態変数の推定結果を見てみましょう。実際の値と推定値を並べてみます。
（なお以降の作業の前にサンプルのtraceプロットとヒストグラムを確認し、収束していると判断しています）



```{r}
state_cmp %>% 
   gather("Var", "Val", -c(Area, YM)) %>% 
   ggplot(., aes(x = YM, y = Val, colour = Var)) +
   geom_line() +
   facet_wrap(~Area)
```

おぉ、かなり精度良く推定できているようですね！状態変数の初期値や分散の推定値はどうでしょうか？

```{r}
ests %>% 
   data.frame %>% 
   select(mean) %>% 
   rename("Estimated" = mean) %>% 
   mutate("Par" = rownames(ests)) %>% 
   filter(Par %in% t0_rows) %>% 
   mutate("True" = c(state_t0, var_state_t0)) %>% 
   mutate("Simulated" = c(
      mean(DF[c(1, 49, 97, 145, 193), "True_s"]),
      var(DF[c(1, 49, 97, 145, 193), "True_s"])
   )) %>% 
   select(Par, True, Simulated, Estimated)
```

真の値がそれぞれ`3`および`1`であったのに対し、生成されたデータでは`3.7`および`0.85`でした。推定された値は`3.7`および`1.3`で、分散がやや過大に推定されているようです。ただし以下に示すように、推定値の95%信用区間も結構広いため、逸脱しているとまでは言えないようです。

```{r}
ests %>% 
   data.frame %>% 
   select(X2.5., X97.5.) %>% 
   rename("Lower95" = X2.5.,
          "Upeer95" = X97.5.) %>% 
   mutate("Par" = rownames(ests)) %>% 
   filter(Par %in% t0_rows) %>% 
   select(Par, everything())
```


続いて回帰係数はどうでしょうか。

```{r}
beta_par <- 
   ests %>% 
   data.frame %>% 
   select(mean) %>% 
   mutate("Par" = rownames(ests)) %>% 
   filter(Par %in% beta_rows)

beta_cmp <- data.frame(
   True = beta_ad,
   Est = beta_par$mean
)

ggplot(beta_cmp, aes(x = True, y = Est)) +
   geom_point() +
   coord_fixed()
```

こちらも、事前に設定した回帰係数と推定値が似通っているようです。数値を確認しても、良い精度で推定できていることが確認できます。

```{r}
ests %>% 
   data.frame %>% 
   select(mean) %>% 
   mutate("Par" = rownames(ests)) %>% 
   filter(Par %in% beta_rows) %>% 
   bind_cols("True" = beta_ad) %>% 
   select(Par, True, mean)
```

最後に、回帰係数の事前分布についても見ておきましょう。

```{r}
ests %>% 
   data.frame %>% 
   select(mean) %>% 
   mutate("Par" = rownames(ests)) %>% 
   filter(Par %in% b0_rows) %>% 
   bind_cols("True" = c(mu_beta, var_beta)) %>% 
   select(Par, True, mean)
```

回帰係数の事前分布の分散はちょっと大きく推定されているようですが、平均は近しい値となっているようです。


#### 終わりに

以上、「階層ベイズと状態空間モデルを合わせて取り扱いたい」という試みでしたが、結果としては概ね満足の行くものになったと思います。
序盤に書いた通り、階層ベイズ + 状態空間モデルのような非常に複雑なモデルであっても、stanを使えば非常に簡単に推定が可能です。

これまで広告効果の推定についていくつか記事を書いてきましたが、実はゴールとなるモデルとしてはこれを想定していました。
あとはこのモデルにこれまで紹介してきたようなAdStock効果の推定を組み込めば、試してみたかったモデルは一通り完了することになります。
これについても追って紹介したいと思っています。

